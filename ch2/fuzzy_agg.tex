% Para qué usamos en el MDCM el fuzzy? Para manejar Uncertainty y subjectivity.

% Information integration (aggregation)

% Distance measures

% Preference relations

% \signal{
%     Entropy desde el punto de vista de la posibilidad es el que más específico es. Es máxima si el conjunto tiene un unico punto, entonces sabes que es super especifico, ese concepto corresponde a ese unico punto y a nada más. Desde el punto de vista de la informacion es cuanto más informativo, mayor entropía. Desde el punto de vista de la probabilidad es cuanto más te distingue los sucesos: la delta de dirac tiene mínimo y la uniforme máximo o algo así era. 
%     Eso lo tengo que repasar.
%     }\\


% Cosas para mencionar sobre fuzzy en MCDM:

% \signal{OWA operators, y sus generalizaciones. Orness, andness, orlike y andlike.

% Entropía de un OWA, quantifiers

% Fuzzy implication operators para la importancia de los OWA

% Fuzzy ratings, que es como tener 2 fuzzy weights y así incorporas la linguistic variable.

% Fuzzy reasoning: tienes fuzzy rules y las agregas con un OWA por ejemplo. Puedes hacer la implicación y luego agregar o agregar y luego hacer la implicación.

% MICA operators es la clase más general de operators en fuzzy modeling.

% 3 mecanismos de MISO fuzzy system

% Compositional rule of inference

% Generalized method of case inference rule

% Interdependencia de los criterios!

% Lo de que la importancia es relativa, puedo tener unos criterios sí y otros no y tal y que eso me cambie el grado de importancia.}

\signal{Aquí pensaba definir agregación en general como una función. Luego presento los OWAs y sus variaciones. Hasta aquí sí que lo tengo claro.

Pero para seguir, quería simplemente poner los métodos que vaya a usar en la aplicación práctica del tema 3. No sé si un fuzzy TOPSIS o ELECTRE o alguno de esos que tengo en el diagrama de arriba. O si por el contrario puedo continuar con generalizaciones de los OWA pero eso ya sería meterme otra vez con fuzzy measures y acabaría en la integral de Choquet, de Sugeno o de Shilkret o alguna de esas. También otro método sería meterme en lo de reglas de inferencia, ya que he empezado con lo de Pavelka y el razonamiento aproximado, podría ser interesante igual.}

\section{Fuzzy Aggregation}
\label{subsec:fuzzy_aggregation}

In the context of multi-criteria decision making, after evaluating each alternative against every criterion, the next logical step is to combine these individual assessments into a single, comprehensive value for each alternative. This process is known as aggregation. An aggregation function takes a collection of numerical inputs, representing the performance scores of an alternative, and maps them to a single output value. This overall score should ideally be a meaningful representation of the inputs, allowing for a final ranking of the alternatives. The most common aggregation function is the weighted average (WA), where each criterion's score is multiplied by a predefined weight representing its importance, and the results are summed.

However, the weighted average has a fundamental limitation, its weights are fixed to specific criteria. This approach does not allow for modeling the decision maker's attitude, such as optimism or pessimism, towards the performance scores themselves. To address this, the Ordered Weighted Averaging (OWA) operator, introduced by Yager, provides a more flexible framework. The core innovation of the OWA operator is that it disassociates the weights from the criteria and instead associates them with the ordered positions of the values. That is, weights are assigned based on a value's rank (e.g., to the highest value, the second highest, and so on) rather than to the criterion it came from.

\begin{definition}[Ordered Weighted Averaging (OWA) Operator]
Let $(a_1, a_2, \dots, a_n)$ be a collection of values to be aggregated. The OWA operator is a mapping $\text{OWA}: \mathbb{R}^n \to \mathbb{R}$ defined by a weighting vector $W = (w_1, w_2, \dots, w_n)$ such that $w_i \in [0, 1]$ and $\sum_{i=1}^{n} w_i = 1$. The aggregated value is given by:
\[
\text{OWA}(a_1, a_2, \dots, a_n) = \sum_{j=1}^{n} w_j b_j
\]
where $b_j$ is the $j$-th largest value in the collection $(a_1, a_2, \dots, a_n)$.
\end{definition}

The key to the OWA operator's flexibility lies in the determination of the weighting vector $W$. By changing the distribution of the weights, one can model a wide spectrum of aggregation behaviors. For instance, an optimistic decision maker, who focuses on the best outcomes, would assign higher weights to the first components of the vector $W$, thereby giving more importance to the highest-ranked values ($b_1, b_2, \dots$). Conversely, a pessimistic decision maker would assign higher weights to the last components, emphasizing the worst-performing criteria. A standard arithmetic mean is recovered by setting all weights equal, $w_j = 1/n$. This ability to model the decision maker's attitude is a significant advantage over the simple weighted average.

The process of defining the weights can be guided by several methods. A fundamental concept in this regard is the measure of \textit{orness}, which quantifies the degree of optimism of the operator. It is calculated as $\text{orness}(W) = \sum_{j=1}^{n} w_j \frac{n-j}{n-1}$. An orness of 1 corresponds to pure optimism (like the MAX operator, where $w_1=1$), an orness of 0 corresponds to pure pessimism (like the MIN operator, where $w_n=1$), and an orness of 0.5 reflects a neutral attitude (like the mean). More intuitively, weights can be derived from linguistic quantifiers, such as "most", "at least half", or "about three". These quantifiers can be mathematically modeled to generate a corresponding weighting vector $W$, allowing the decision maker to specify their aggregation strategy in a natural and understandable way.

The OWA operator has inspired numerous extensions and variations, such as the Ordered Weighted Geometric (OWG) operator for contexts where a multiplicative aggregation is more suitable, and hybrid operators like the Induced OWA (IOWA) and the Combined Weighted Averaging (CWA), which seek to reintroduce the importance of the criteria themselves alongside the attitudinal weighting. It is important to note, however, that OWA and its direct variants are based on an additive measure of importance, since the weights must sum to one. This framework assumes that the criteria are preferentially independent. It does not capture more complex interactions between criteria, such as synergy, where the combined effect of two criteria is greater than their sum, or redundancy. Modeling such relationships requires non-additive fuzzy measures and more complex aggregation tools, like the Choquet or Sugeno integrals, which are beyond the scope of this discussion.